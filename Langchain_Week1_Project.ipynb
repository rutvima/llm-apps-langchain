{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13QRnUTv749o_bPZhXJmAdZlHYzSRPOEv","timestamp":1739729639423}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c1901bd8a25b47eaa027608c1e0109b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe4c63c4b4fa4f1095f62bc72df06fe3","IPY_MODEL_a74efece9fa048b0a934c53a6201a5d0","IPY_MODEL_ffab70b63b264959a0cc391245a6a1a0"],"layout":"IPY_MODEL_cdd5b90cc96e458aa8215292f74a1570"}},"fe4c63c4b4fa4f1095f62bc72df06fe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39dbd670cc6e481aa368fced34abd035","placeholder":"​","style":"IPY_MODEL_c844779963a341549bc3227165990066","value":""}},"a74efece9fa048b0a934c53a6201a5d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e18022e193f54025b7d88dd24eed7760","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4b6419016c2423190372aadc1478587","value":1}},"ffab70b63b264959a0cc391245a6a1a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7347f326093443709c4583ffb9c748ac","placeholder":"​","style":"IPY_MODEL_025eef662e764694b7a67b135cf73acf","value":" 12/? [00:50&lt;00:00,  4.42s/it]"}},"cdd5b90cc96e458aa8215292f74a1570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39dbd670cc6e481aa368fced34abd035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c844779963a341549bc3227165990066":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e18022e193f54025b7d88dd24eed7760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b4b6419016c2423190372aadc1478587":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7347f326093443709c4583ffb9c748ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"025eef662e764694b7a67b135cf73acf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/sidhusmart/Uplimit_Langchain_Course/blob/main/Week1/Langchain_Week1_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["This notebook is part of the course: [LLM Apps with Langchain](https://uplimit.com/course/llm-apps-with-langchain) and is created by Sidharth Ramachandran as the project for Week 1 of the course."],"metadata":{"id":"h-T0u92GVJE6"}},{"cell_type":"markdown","source":["# Let's build \"PillPal\" - a Telegram bot and website that allows users to ask questions based on the Patient Information Leaflet (PIL) or drug guide that comes with any medication."],"metadata":{"id":"BmgRqB0z3JLd"}},{"cell_type":"markdown","source":["![Package Information Leaflet](https://i.ibb.co/ZSdGyjV/ima-image-36904.jpg)"],"metadata":{"id":"zcmYA3M8aGp3"}},{"cell_type":"markdown","source":["I'm sure you have all come across the thin piece of folded paper that is part of every drug prescription box. Usually the text is in very small print and typically provides information about dosages, side effects, storage instructions and much more. They are hard to read and understand and requires some effort to get answers to common questions a patient might have. What if we could create a product that answers these questions and actually makes the medical information more accessible and easier to understand - enter PillPal!"],"metadata":{"id":"oZ-FEcb8SjNy"}},{"cell_type":"markdown","source":["In the process of building PillPal, we will go through the following stages and on the way learn more about LLM Apps and their typical life-cycle.\n","\n","1. BUILD the app: this is where we first test the idea, try multiple options for various parts of the pipeline till we are satisfied to a reasonable extent that the product works.\n","2. DEPLOY & MONITOR the app: this is where we want to make the app available to our first users, monitor it's behaviour and discover edge cases.\n","3. EVALUATE & IMPROVE the app: this is the final and ongoing stage where we will build an evaluation suite that constantly checks whether our app is working as expected and perform experiments."],"metadata":{"id":"0fEvG823VR9F"}},{"cell_type":"markdown","source":["We will use Langchain to develop the app, deploy it as a Telegram bot/ Website and use Langsmith to monitor, evaluate and improve the product. Please consider PillPal as the chosen example/ case study to illustrate the process but feel free to adapt this project ot build any app of your choice!\n","\n","# # 👨‍🎓 Learner Project\n","\n","In the project walkthrough session we will go through the various steps of the project with an example of one of the drugs. The learner project is to implement the same steps for a different drug OR any other PDF of your choice. Concretely, here are steps that you need to do:\n","\n","1. Identify a PDF that you would like to ask questions about. Suggestion: choose another drug or medication that you are familiar with.\n","2. Upload and use that PDF as you go through this notebook.\n","3. Make use of the sections and flow as a guide but you are expected to update and write code to complete the RAG project for your PDF.\n","4. Feel free to adapt any sections to add more functionality or adapt for your use case/ PDF."],"metadata":{"id":"I2S69-R7aK0k"}},{"cell_type":"markdown","source":["# Step 0: Necessary libraries and setup"],"metadata":{"id":"ruybS1MUZ3--"}},{"cell_type":"code","source":["# Install the necessary libraries to get it out of the way\n","!pip install langchain\n","!pip install langchain-community\n","!pip install langchain-openai\n","!pip install faiss-cpu\n","!pip install pymupdf\n","!pip install grandalf\n","!pip install gradio"],"metadata":{"id":"JbQIsr6r6kOq","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739748028137,"user_tz":-60,"elapsed":62985,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"929ca82c-792d-4b8c-ba6a-7c4823188936"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n","Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n","Collecting langchain-community\n","  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.35)\n","Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.12)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n","  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\n","Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n","Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n","Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n","Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.17 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.35)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai) (0.3.8)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai) (9.0.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai) (4.12.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain-openai) (2.10.6)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain-openai) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain-openai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.35->langchain-openai) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.35->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.35->langchain-openai) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n","Downloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n","Successfully installed langchain-openai-0.3.6 tiktoken-0.9.0\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n","Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.10.0\n","Collecting pymupdf\n","  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n","Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pymupdf\n","Successfully installed pymupdf-1.25.3\n","Collecting grandalf\n","  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.2.1)\n","Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: grandalf\n","Successfully installed grandalf-0.8\n","Collecting gradio\n","  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.7.0 (from gradio)\n","  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n","Collecting markupsafe~=2.0 (from gradio)\n","  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n","Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.16.0-py3-none-any.whl (62.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","  Attempting uninstall: markupsafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.16.0 gradio-client-1.7.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"]}]},{"cell_type":"markdown","source":["### OpenAI Initialization"],"metadata":{"id":"9kCSk1SucCyS"}},{"cell_type":"markdown","source":["You will be provided an API key by the Course Manager. If you are not able to find it, please reach out on ask for help on the Discussion forums.\n","\n","Please note that this is a shared API key for the entire class, so please make sure to use it responsibly. We will also show you steps below to add it to your secret keys so that it is not revealed in any way."],"metadata":{"id":"8SmzMEqgcFg2"}},{"cell_type":"markdown","source":["Once you have obtained the API key, you can add it to the Google Colab instance by adding it to the Secrets section as shown below. Please use the variable name 'OPENAI_API_KEY' and paste the value that you copied before.\n","\n","![Add to Google Colab](https://i.ibb.co/Cb57Sxq/Xnapper-2024-06-09-21-42-30.png)"],"metadata":{"id":"4R3CUqKij-mo"}},{"cell_type":"code","source":["# Initialize this in Colab earlier if you need observability/tracing using LangSmith\n","import os\n","from google.colab import userdata\n","\n","os.environ['LANGSMITH_TRACING'] = 'true'\n","os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n","os.environ['LANGSMITH_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n","os.environ['LANGSMITH_PROJECT'] = \"pr-uplimit-rag\"\n","os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"KFP0FNx03eh4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 1: Building the PillPal bot"],"metadata":{"id":"XS1dSf8E6ZUS"}},{"cell_type":"markdown","source":["The patient information leaflets/ drug booklets are typically available in the form of PDFs from the drug manufacturers website or from a central repository like in the [UK](https://www.medicines.org.uk/) or the [US](https://dailymed.nlm.nih.gov/). While you should be able to find them relatively easily through an Internet Search, we also include the medical booklet PDFs for two drugs with this code repository to use in the project."],"metadata":{"id":"0It6mAFmW4Qj"}},{"cell_type":"markdown","source":["One of the best aspects of using Langchain is that it provides a lot of in-built integrations for most common development tasks while building LLM apps. We will make use of several of them during this project, starting with the PDF loader which we will use to read in the medical booklet PDF file. For this example, we have chosen the PIL for Ozempic - a new drug that decreses the risk of heart disease in overweight patients but has been in the news recently for also being a weight loss solution."],"metadata":{"id":"DXAlB_g8ZGM6"}},{"cell_type":"markdown","source":["As we are still in the notebook environment - please follow the below steps to upload the PDF document into the Colab environment.\n","\n","![Upload PDF](https://i.ibb.co/jgDBwY4/Xnapper-2024-06-09-21-58-08.png)"],"metadata":{"id":"vtqgnSjFZ7RP"}},{"cell_type":"markdown","source":["## 📝 Learner Task:\n","\n","In the following section, you have to load in your PDF using any of the document loaders available from the Langchain Community package. For example: you could use the `PyMuPDFLoader` for managing PDFs.\n","\n","Your code should do the following:\n","- Load the PDF\n","- Identify the number of pages\n","- Print one of the pages with the associated metadata"],"metadata":{"id":"S505i8I5MbI2"}},{"cell_type":"code","source":["## Your code here\n","from langchain_community.document_loaders import PyMuPDFLoader\n","\n","## Load the PDF\n","loader = PyMuPDFLoader(\"/content/pil.13799.pdf\")\n","documents = loader.load()\n","\n","# Identify the number of pages\n","num_pages = len(documents)\n","print(f\"The PDF has {num_pages} pages.\")\n","\n","# Print one of the pages with the associated metadata\n","print(documents[0])\n"],"metadata":{"id":"n2nJ6tyN7758","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739748489035,"user_tz":-60,"elapsed":2290,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"a1467183-1f9b-43f7-fbde-5843bfd9e02d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The PDF has 16 pages.\n","page_content='GB – Wegovy PIL– Version 8 \n","Package leaflet: Information for the patient  \n"," \n","wegovy FlexTouch \n","0.25 mg, 0.5 mg, 1 mg, 1.7 mg and 2.4 mg \n","solution for injection in pre-filled pen \n","semaglutide \n"," \n","This medicine is subject to additional monitoring. This will allow quick identification of new \n","safety information. You can help by reporting any side effects you may get. See the end of section 4 \n","for how to report side effects. \n"," \n","Read all of this leaflet carefully before you start using this medicine because it contains \n","important information for you. \n","– \n","Keep this leaflet. You may need to read it again. \n","– \n","If you have any further questions, ask your doctor, pharmacist or nurse. \n","– \n","This medicine has been prescribed for you only. Do not pass it on to others. It may harm them, \n"," \n","even if their signs of illness are the same as yours. \n","– \n","If you get any side effects, talk to your doctor, pharmacist or nurse. This includes any possible \n"," \n","side effects not listed in this leaflet. See section 4. \n"," \n","What is in this leaflet \n","1. \n","What wegovy is and what it is used for  \n","2. \n","What you need to know before you use wegovy  \n","3. \n","How to use wegovy   \n","4. \n","Possible side effects  \n","5. \n","How to store wegovy  \n","6. \n","Contents of the pack and other information \n"," \n","1. What wegovy is and what it is used for \n"," \n","What wegovy is \n","wegovy is a medicine for weight loss and weight maintenance that contains the active substance \n","semaglutide. It is similar to a natural hormone called glucagon-like peptide-1 (GLP-1) that is released \n","from the intestine after a meal. wegovy works by acting on receptors in the brain that control your \n","appetite, causing you to feel fuller and less hungry and experience less craving for food. This will help \n","you eat less food and reduce your body weight. wegovy should be used with a reduced calorie meal \n","plan and increased physical activity. \n"," \n","What wegovy is used for \n"," \n","Weight management \n","wegovy is used for weight loss and weight maintenance in addition to diet and physical activity in \n","adults, who have: \n","• \n","a BMI of 30 kg/m² or greater (with obesity) or \n","• \n","a BMI of 27 kg/m² and less than 30 kg/m² (overweight) and weight-related health problems. \n"," \n","BMI (Body Mass Index) is a measure of your weight in relation to your height. \n"," \n","wegovy is used together with diet and physical activity for weight management in adolescents ages \n","12 years and above, who have \n","• \n","obesity  \n","• \n","body weight >60kg  \n","As an adolescent patient, you should only continue using wegovy if you have lost at least 5% of your  \n","BMI after 12 weeks on the 2.4 mg dose or maximum tolerated dose (see section 3). Consult your \n","doctor before you continue.' metadata={'producer': 'Adobe PDF Library 24.2.159', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2024-10-11T12:52:38+01:00', 'source': '/content/pil.13799.pdf', 'file_path': '/content/pil.13799.pdf', 'total_pages': 16, 'format': 'PDF 1.6', 'title': 'Hqrdtemplatecleanen v10.1', 'author': 'European Medicines Agency', 'subject': '', 'keywords': '', 'moddate': '2024-10-11T12:52:43+01:00', 'trapped': '', 'modDate': \"D:20241011125243+01'00'\", 'creationDate': \"D:20241011125238+01'00'\", 'page': 0}\n"]}]},{"cell_type":"markdown","source":["The additional metadata like page number and title is relevant to our product because when we answer questions: we can also point users to specific sections of the original document which they can refer to for more clarity."],"metadata":{"id":"H1ksk-czaxN5"}},{"cell_type":"markdown","source":["Our next step is to index this entire document which we do with the help of OpenAI embeddings. However, before we do that we need to split document into chunks so that at the time of retrieval we are identifying the correct parts of the document. We use one of the in-built Langchain components that allows us to split based on characters based on our specifications.\n","\n","We have chosen to split the entire document into chunks of length 2000 characters and also ensure an overlap of 200 characters. This makes sure that we are not loosing any information when splitting up the document. As we will see later, this is one of the parameters that we can control and could have an influence on the performance of our product."],"metadata":{"id":"8eI1CZqcbF7S"}},{"cell_type":"markdown","source":["## 📝 Learner Task:\n","\n","In the following section, you have to decide the best chunking strategy for your PDF and use case. For instance, you could make use of the `RecursiveCharacterTextSplitter` to work with text documents. It's important to also decide what are reasonable values for `chunk_size` and `chunk_overlap`. In the project walkthrough we provide some suggested values."],"metadata":{"id":"PbkgyfD9NryJ"}},{"cell_type":"code","source":["## Your code here\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Initialize the text splitter with desired chunk size and overlap\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=2000,\n","    chunk_overlap=200,\n",")\n","\n","# Split the documents into chunks\n","splits = text_splitter.split_documents(documents)"],"metadata":{"id":"4xMZXPdM9fae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We are optimising for retrieval - i.e. how fine-grained is the context that we can retrieve so that we can answer the question that our user is asking. In this case, it might be better to have a smaller chunk because you are then narrowing down on the perfect part of the text where this information is present."],"metadata":{"id":"7tqcP7ljBQsK"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from google.colab import userdata\n","\n","## Define the embedding model below by using the `text-embedding-3-small` model\n","\n","embedding_model = OpenAIEmbeddings(model='text-embedding-3-small', openai_api_key=userdata.get('OPENAI_API_KEY'))"],"metadata":{"id":"UBVkp6TbaZDr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A huge advantage of using Langchain is that it provides integrations with several types of vector databases like Chroma, Pinecone and more. In this project, we make use of the FAISS library from Facebook/Meta as a simple choice. In the following section, we combine the steps of generating the embedding value for each document chunk and then also storing it into the FAISS vector database."],"metadata":{"id":"IDaUK7NbE8J4"}},{"cell_type":"code","source":["from langchain_community.vectorstores import FAISS\n","\n","vector_store = FAISS.from_documents(documents=splits, embedding=embedding_model)"],"metadata":{"id":"NDV_HnMFFJfb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We have our documents indexed and we can directly start retrieving documents based on a similarity search with a target query."],"metadata":{"id":"_nI7cwlNdiBr"}},{"cell_type":"code","source":["search_result = vector_store.similarity_search_with_relevance_scores(query=\"What is the recommended dosage?\", k=4)\n","search_result"],"metadata":{"id":"x1_wRhCQJBLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739748811846,"user_tz":-60,"elapsed":471,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"ed260270-5d1d-445f-c689-faf95ab3ebb1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Document(id='03450f77-1154-4b22-8b0c-799e9f29402f', metadata={'producer': 'Adobe PDF Library 24.2.159', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2024-10-11T12:52:38+01:00', 'source': '/content/pil.13799.pdf', 'file_path': '/content/pil.13799.pdf', 'total_pages': 16, 'format': 'PDF 1.6', 'title': 'Hqrdtemplatecleanen v10.1', 'author': 'European Medicines Agency', 'subject': '', 'keywords': '', 'moddate': '2024-10-11T12:52:43+01:00', 'trapped': '', 'modDate': \"D:20241011125243+01'00'\", 'creationDate': \"D:20241011125238+01'00'\", 'page': 2}, page_content='Week 1–4 \\n0.25 mg \\nWeek 5–8 \\n0.5 mg \\nWeek 9–12 \\n1 mg \\nWeek 13–16 \\n1.7 mg \\nFrom week 17  \\n2.4 mg \\n \\nYour doctor will assess your treatment on a regular basis. \\n \\nAdolescents (above 12 years of age) \\nFor adolescents, the same dose escalation schedule as for adults should be applied (see above). The \\ndose should be increased until 2.4 mg (maintenance dose) or maximum tolerated dose has been \\nreached. Weekly doses higher than 2.4 mg are not recommended. \\n \\nHow wegovy is given \\nwegovy is given as an injection under the skin (subcutaneous injection). Do not inject it into a vein or \\nmuscle. \\n• \\nThe best places to give the injection are the upper arms, stomach or upper legs. \\n• \\nBefore you use the pen for the first time, ask your doctor or nurse how to use it. \\n \\nDetailed instructions for use are on the other side of this leaflet.'),\n","  0.2626986264843689),\n"," (Document(id='f9976d1b-2b69-40ad-9eca-1c372a406695', metadata={'producer': 'Adobe PDF Library 24.2.159', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2024-10-11T12:52:38+01:00', 'source': '/content/pil.13799.pdf', 'file_path': '/content/pil.13799.pdf', 'total_pages': 16, 'format': 'PDF 1.6', 'title': 'Hqrdtemplatecleanen v10.1', 'author': 'European Medicines Agency', 'subject': '', 'keywords': '', 'moddate': '2024-10-11T12:52:43+01:00', 'trapped': '', 'modDate': \"D:20241011125243+01'00'\", 'creationDate': \"D:20241011125238+01'00'\", 'page': 2}, page_content='You should not use this medicine if you are breast-feeding, as it is unknown if it passes into breast \\nmilk.  \\n \\nDriving and using machines \\nwegovy is unlikely to affect your ability to drive and use machines. Some patients may feel dizzy \\nwhen taking wegovy mainly during the first 3 months of treatment (see section 4). If you feel dizzy \\nyou should not drive or operate machines until you feel better. If you need any further information, \\ntalk to your doctor, pharmacist or nurse. \\n \\nFor diabetics using this medicine in combination with a sulfonylurea or insulin, low blood sugar \\n(hypoglycaemia) may occur which may reduce your ability to concentrate. Do not drive or use \\nmachines if you get any signs of low blood sugar. See section 2, ‘Warning and precautions’ for \\ninformation on increased risk of low blood sugar and section 4 for the warning signs of low blood \\nsugar. Talk to your doctor for further information.  \\n \\nSodium content \\nThis medicine contains less than 1 mmol sodium (23 mg) per dose, i.e. essentially ‘sodium-free’.  \\n \\n3. \\nHow to use wegovy   \\nAlways use this medicine exactly as your doctor has told you. Check with your doctor, pharmacist or \\nnurse if you are not sure. \\n \\nHow much to use \\nAdults \\nThe recommended dose is 2.4 mg once weekly. \\nYour treatment will start at a low dose which will be gradually increased over  \\n16 weeks of treatment as follows: \\n• \\nWhen you first start using wegovy, the starting dose is 0.25 mg once weekly. \\n• \\nYour doctor will instruct you to gradually increase your dose every 4 weeks until you reach the \\nrecommended dose of 2.4 mg once weekly. \\n• \\nOnce you reach the recommended dose of 2.4 mg, do not increase this dose further. \\n \\nYou will be told to follow the table below. \\n \\nDose escalation \\nWeekly dose \\nWeek 1–4 \\n0.25 mg \\nWeek 5–8 \\n0.5 mg \\nWeek 9–12 \\n1 mg \\nWeek 13–16 \\n1.7 mg \\nFrom week 17  \\n2.4 mg \\n \\nYour doctor will assess your treatment on a regular basis. \\n \\nAdolescents (above 12 years of age)'),\n","  0.17864466073691077),\n"," (Document(id='1a4401f6-e111-43df-b0e4-c3b82ac0f3a0', metadata={'producer': 'Adobe PDF Library 24.2.159', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2024-10-11T12:52:38+01:00', 'source': '/content/pil.13799.pdf', 'file_path': '/content/pil.13799.pdf', 'total_pages': 16, 'format': 'PDF 1.6', 'title': 'Hqrdtemplatecleanen v10.1', 'author': 'European Medicines Agency', 'subject': '', 'keywords': '', 'moddate': '2024-10-11T12:52:43+01:00', 'trapped': '', 'modDate': \"D:20241011125243+01'00'\", 'creationDate': \"D:20241011125238+01'00'\", 'page': 11}, page_content='The dashed line ( ) in the dose counter will guide you to your dose. \\nThe dose selector clicks differently when turned forward, backwards \\nor past your dose. You will hear a ‘click’ every time you turn the \\ndose selector. Do not set the dose by counting the number of clicks \\nyou hear.  \\n J \\nDashed line \\n \\nWhen your prescribed dose lines up with the dose pointer, you \\nhave selected your dose. In this picture, the dose \\n is shown \\nas an example.  \\nIf the dose counter stops before you reach your prescribed dose, see \\nthe section ‘Do you have enough wegovy?’ below these \\ninstructions.  \\n K \\nExample: \\n0.25 mg \\nselected \\n \\n \\nChoose your injection site \\nChoose upper arms, stomach or upper legs (keep a 5 cm distance \\nfrom your belly button). \\nYou may inject in the same body area each week, but make sure it is \\nnot in the same spot as used the last time. \\n \\nUpper arms \\nStomach \\nUpper legs'),\n","  0.12619400358316446),\n"," (Document(id='b0ff25f8-272f-4ed7-b54e-d85124d46947', metadata={'producer': 'Adobe PDF Library 24.2.159', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2024-10-11T12:52:38+01:00', 'source': '/content/pil.13799.pdf', 'file_path': '/content/pil.13799.pdf', 'total_pages': 16, 'format': 'PDF 1.6', 'title': 'Hqrdtemplatecleanen v10.1', 'author': 'European Medicines Agency', 'subject': '', 'keywords': '', 'moddate': '2024-10-11T12:52:43+01:00', 'trapped': '', 'modDate': \"D:20241011125243+01'00'\", 'creationDate': \"D:20241011125238+01'00'\", 'page': 12}, page_content='3 Inject your dose \\nInsert the needle into your skin. \\nMake sure you can see the dose counter. Do not cover it with your \\nfingers. This could interrupt the injection. \\n \\n \\nPress and hold down the dose button until the dose counter \\nshows \\n.  \\nKeep pressing the dose button with the needle in your skin and \\nslowly count to 6. The \\n must line up with the dose pointer. You \\nmay hear or feel a click when the dose counter returns to \\n. \\n M \\n N \\nCount slowly \\n1-2-3-4-5-6 \\n \\nL'),\n","  0.10492518653802096)]"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["In this case, we have chosen to use cosine similarity as our distance metric and the similarity values are also shown along with the retrieved results. You will notice that not many of the retrieved chunks actually contain the text \"Weight Loss\" - and this is because we are not doing a word-based search but rather semantic search. This is what vector databases allow us to do. However, it is also possible that at times we want to match exact query terms and then we will follow a hybrid search approach. This is again one of the levers that we have to expriment with to determine what is necessary for our product. So it's important that you are able to determine what is the best method for you to choose - depends a lot on your use-case."],"metadata":{"id":"SxPewWEYLG1R"}},{"cell_type":"markdown","source":["### Creating the QnA RAG chain"],"metadata":{"id":"H_MbjNwSaEOn"}},{"cell_type":"markdown","source":["Let's move on to complete our product by integrating with the LLM. Here again, we rely heavily on the building blocks that Langchain already provides us to put together the entire chain.\n","\n","The chain consists of multiple parts - a Retriever, followed by a Prompt Template where the retrieved documents are added and then the call to the LLM. The response from the LLM is what we finally show as output to the user. There are multiple steps in creating a RAG application. We break it down to make it easier to understand and follow."],"metadata":{"id":"i7eiBrgeetbs"}},{"cell_type":"markdown","source":["## 📝 Learner Task:\n","Creating the Prompt Template. In the section below, please create the PromptTemplate that will be used for your RAG application. The `ChatPromptTemplate` has become the standardized way to use chat-based LLMs and consists of a `SystemMessage`, followed by the `HumanMessage` with the response from the LLM stored in the `AIMessage`. We have provided the necessary imports in the below cell and request you to create the variable `qna_prompt_template` that will be used in the application."],"metadata":{"id":"HlqW4TbcOfBw"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain.prompts import SystemMessagePromptTemplate\n","from langchain.prompts import HumanMessagePromptTemplate\n","\n","## Your code here\n","\n","# System message prompt template\n","system_message_prompt = SystemMessagePromptTemplate.from_template(\n","    \"You are an expert assistant that answers questions about medical information based on the provided context. Answer only from the given context. If the answer is not found in the context, say 'I cannot answer the question based on the provided context.'\"\n",")\n","\n","# Human message prompt template\n","human_message_prompt = HumanMessagePromptTemplate.from_template(\n","    \"\"\"Context: {context}\n","\n","    Question: {question}\"\"\"\n",")\n","\n","# Chat prompt template\n","qna_prompt_template = ChatPromptTemplate.from_messages(\n","    [system_message_prompt, human_message_prompt]\n",")"],"metadata":{"id":"5cv_Fi0IPfn5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After the PromptTemplate, the next step is to define the LLM Model that you would like to run with. We provide the OpenAI API models as the default option and make use of `gpt-4o-mini`. We also set the `temperature` value to 0 as we do not want the model to be creative but rather answer based on the retrieved context from the PDF."],"metadata":{"id":"iumOVFV4Pk_X"}},{"cell_type":"code","source":["llm = ChatOpenAI(model_name=\"gpt-4o-mini\",\n","                 temperature=0,\n","                 openai_api_key=userdata.get('OPENAI_API_KEY'))"],"metadata":{"id":"9-wDIb1gQI7E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The next step is to initilize the retriever part of our application that will fetch the relevant documents from the PDF. Recall that we have already created the embeddings for our document chunks and stored it using the FAISS vectorstore. In this step, we only specify that vectorestore to be our retriever."],"metadata":{"id":"nDlnYaodQPeU"}},{"cell_type":"code","source":["retriever = vector_store.as_retriever()"],"metadata":{"id":"hz_SleAiQrTi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["One additional step that we need to also consider is that when the documents are retrieved from the FAISS vectorstore, they are in the form of a list of documents. These document objects contain a lot more information other than the content like Metadata. Assuming we are performing a simple retrieval, the context that we want to pass to the LLM is only the text content. Therefore we write an additional function that combines only the retrieved text content that can be used to pass in the context of our PromptTemplate.\n","\n","Please note that you could also choose to filter the retrieved documents based on the Metadata. For instance, if you only want to see results from Page 5 and beyond of the PDF - then you can also adapt this function to reflect that."],"metadata":{"id":"zEtojMFZQyjR"}},{"cell_type":"code","source":["def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)"],"metadata":{"id":"b64wwSooQv2f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The final stage is to put together the various elements that we have defined above to create our pipeline. The key aspect to note here is that the input question is used twice during the process -> at the first instance to retrieve a list of the relevant context and the second instance when it is passed to the LLM as the question that needs to be answered.\n","\n","So we make use of the `itemgetter` to retrieve the content of the question and pass to the retriever to get the relevant context. On the other hand, we make use of the `RunnablePassthrough` class to directly pass the input question to the subsequent operation. At the end we also add the `StrOuputParser` to get the actual text message of the response rather than the whole AIMessage."],"metadata":{"id":"0VVUVqJARaYJ"}},{"cell_type":"code","source":["from operator import itemgetter\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","\n","rag_chain = (\n","    {\"context\": itemgetter(\"input\") | retriever | format_docs,\n","     \"question\": RunnablePassthrough()}\n","    | qna_prompt_template\n","    | llm\n","    | StrOutputParser()\n",")"],"metadata":{"id":"VI7UOE70LleJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Please check that your entire chain works by providing your questions and invoking the RAG chain."],"metadata":{"id":"t5YW6DF-Sog3"}},{"cell_type":"code","source":["question = \"What should you do if you use more wegovy than recommended?\"\n","rag_chain.invoke({\"input\": question})"],"metadata":{"id":"ftZIkyQISoAt","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1739750056357,"user_tz":-60,"elapsed":1684,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"147cb869-8f0b-4a4a-a0b3-f06566dcbf63"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'If you use more wegovy than you should, talk to your doctor straight away. You may get side effects such as feeling sick (nausea).'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## 📝 Learner Task:\n","If you run into errors as you develop, visualizing the chain is an easy way to discover any issues. This visualization helps us understand the entire flow of operations within our application. By graphically representing the connections and interactions between different components we can see how the data flows and in which shape from one path tothe next. It allows for easier debugging and we might be able to pinpoint where modifications might be necessary."],"metadata":{"id":"PBbDadkAT1zB"}},{"cell_type":"code","source":["print (rag_chain.get_graph().print_ascii())"],"metadata":{"id":"l50o8HECL53q","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739750097743,"user_tz":-60,"elapsed":228,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"404fef2e-7dad-401c-cc0c-5212f33fba9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           +---------------------------------+        \n","           | Parallel<context,question>Input |        \n","           +---------------------------------+        \n","                    **              ***               \n","                 ***                   **             \n","               **                        ***          \n","       +--------+                           **        \n","       | Lambda |                            *        \n","       +--------+                            *        \n","            *                                *        \n","            *                                *        \n","            *                                *        \n","+----------------------+                     *        \n","| VectorStoreRetriever |                     *        \n","+----------------------+                     *        \n","            *                                *        \n","            *                                *        \n","            *                                *        \n","    +-------------+                   +-------------+ \n","    | format_docs |                   | Passthrough | \n","    +-------------+*                  +-------------+ \n","                    **              **                \n","                      ***        ***                  \n","                         **    **                     \n","          +----------------------------------+        \n","          | Parallel<context,question>Output |        \n","          +----------------------------------+        \n","                            *                         \n","                            *                         \n","                            *                         \n","                  +--------------------+              \n","                  | ChatPromptTemplate |              \n","                  +--------------------+              \n","                            *                         \n","                            *                         \n","                            *                         \n","                      +------------+                  \n","                      | ChatOpenAI |                  \n","                      +------------+                  \n","                            *                         \n","                            *                         \n","                            *                         \n","                   +-----------------+                \n","                   | StrOutputParser |                \n","                   +-----------------+                \n","                            *                         \n","                            *                         \n","                            *                         \n","                +-----------------------+             \n","                | StrOutputParserOutput |             \n","                +-----------------------+             \n","None\n"]}]},{"cell_type":"markdown","source":["\n","Hopefully, you have managed to build the skeleton for your product. At first just make sure that everything is working in an end to end fashion. After you have achieved that you can move in the direction of improving the answers from the application. This is when you can start experimenting with different aspects of your pipeline to go in the direction of a better solution.\n","\n","We would recommend adapting the following options:\n","\n","- Chunk size:\n","- Retrieval strategy/ metric:\n","- Choice of LLM:"],"metadata":{"id":"VwTao9CgfNrN"}},{"cell_type":"markdown","source":["At the end of this stage, you should be able to have a working prototype of your solution that does reasonably well for the use-case you have in mind.\n","\n","We are still relying on a vibe/gut-feel for the product and cannot rely on quantified metrics. But hopefully you can feel reasonably confident to launch an alpha version of your product to a select group of customers."],"metadata":{"id":"IvhtzIRbfrec"}},{"cell_type":"markdown","source":["# Step 2: Deploying the PillPal bot"],"metadata":{"id":"NlvAHj4bPl6Q"}},{"cell_type":"markdown","source":["Before deploying our product, one of the important steps is to enable tracking and monitoring all the user queries and LLM responses. This is made very easy for us with the help of Langsmith - another part of the Langchain ecosystem.\n","\n","This is one of the cornerstones of our strategy to get towards a more valuable and performing LLM app.\n","\n","Please sign-up on the Langsmith [Website](https://smith.langchain.com/) and you should have access. Next, please navigate to the Settings page from the left side navigation menu and then create your API key there and copy it.\n","\n","<a href=\"https://ibb.co/fN8s3Yp\"><img src=\"https://i.ibb.co/ZgH0Q68/Screenshot-2024-07-26-at-16-12-48.png\" alt=\"Screenshot-2024-07-26-at-16-12-48\" border=\"0\"></a>\n","\n","\n","\n","\n","After that, you can return to the main page and click the New Project icon and copy the environment details that you see.\n","\n","<a href=\"https://ibb.co/th2CQhd\"><img src=\"https://i.ibb.co/yRksdR3/Screenshot-2024-07-26-at-16-12-59.png\" alt=\"Screenshot-2024-07-26-at-16-12-59\" border=\"0\"></a>"],"metadata":{"id":"0X3ZhG3_PqrI"}},{"cell_type":"code","source":["import os\n","os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n","os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n","os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n","os.environ['LANGCHAIN_PROJECT'] = \"YOUR_PROJECT_NAME\""],"metadata":{"id":"WeuJlFzdOnBA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can deploy our LLM app in two different ways -\n","\n","1. A website based chatbot experience - this will be done with the help of Gradio and you do not need to leave the Colab notebook environment\n","2. A telegram chatbot that will run on Github Codespaces (or locally) and will need you to leave the Colab environment"],"metadata":{"id":"-AylFlTLPyp5"}},{"cell_type":"markdown","source":["### Deployed as website chatbot\n","\n","We can deploy our QnA bot on a dedicated website using Gradio, an easy-to-use library for creating interactive machine learning interfaces. One significant advantage of using Gradio in our project is that it integrates seamlessly within the Colab notebook environment. This means you don't need to leave Colab to see your bot in action; you can run it directly from the notebook. Gradio also provides a dedicated URL that you can share with potential beta testers of the QnA bot to get feedback."],"metadata":{"id":"4TQ_kDighGgL"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.schema import AIMessage, HumanMessage\n","import openai\n","import gradio as gr\n","\n","def predict(message, history):\n","    return rag_chain.invoke({\"input\":message})\n","\n","gr.ChatInterface(predict).launch()"],"metadata":{"id":"DDy0V7_eoEYt","colab":{"base_uri":"https://localhost:8080/","height":680},"executionInfo":{"status":"ok","timestamp":1739750310970,"user_tz":-60,"elapsed":8237,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"bf774e04-12d9-44b8-8010-69196569d7f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gradio/components/chatbot.py:290: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://06d57edbb7cdc0aa48.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://06d57edbb7cdc0aa48.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### [OPTIONAL] Deployed as Telegram bot\n","\n","For a wider launch of your LLM app, you can easily make it available as a bot on Telegram - a messenger platform that is used by 500 million users every day. This is useful in the beta/alpha phase because it's way easier to get users to try it in an app that they already use every day. This need not be just Telegram but other popular messengers like Whatsapp, Signal etc. We chose Telegram as it's free and easy to setup.\n","\n","In order to deploy using this option, we will make use of Github codespaces as it's difficult to run it within a synchronous coding environment like Colab. The instructions and code for this will be provided in the live project session."],"metadata":{"id":"_6TnwMSgpNps"}},{"cell_type":"markdown","source":["Please go to the Github repository: https://github.com/sidhusmart/uplimit_langchain.git and clone it so that you can work on it directly. Please note that code in this repository may change frequently so we request you to work only on your cloned version.\n","\n","Once you have cloned it, then you can launch your own Codespaces instance by following the steps as shown in the screenshot. This creates a virtual Visual Studio Code environment in the cloud where we can test our Telegram bot.\n","\n","<a href=\"https://ibb.co/p02fJ1t\"><img src=\"https://i.ibb.co/BzLyqfX/Screenshot-2024-07-26-at-16-05-46.png\" alt=\"Screenshot-2024-07-26-at-16-05-46\" border=\"0\"></a>"],"metadata":{"id":"mmX9Z7lZ8eWT"}},{"cell_type":"markdown","source":["The two important files for you to take a look are `langchain_rag_app.py` and `telegram_response_bot.py` The first python file contains the same RAG functionality that we already built but packaged in functions. The telegram response bot contains the necessary code required to run the Telegram bot.\n","\n","In order to setup and run this app, we have to add the necessary API keys. This is the same process as what we have done previously in the Colab notebook but since we are executing this code in a new environment, we have to add the necessary secrets there as well.\n","\n","We do this via the `.env.dev` file. This file does not exist in the repository by default but instead we have provided the template file called `.env.template`. You need to create a copy of this file and rename it to be `.env.dev` that will contain all the API keys you are going to use during development of the app. Please note that this file is not checked in as we do not want to commit the secrets!  \n","\n","You can observe that there are several environment variables defined in the .env file - most of which we have already setup. You can use the same values for those keys again.\n","\n","However, there is one additional API key that is required to work with the Telegram API. In order to get the Telegram bot API key, you need to follow these steps:\n","\n","1. You must have a Telegram account and access to the App - Web or Mobile versions would also work.\n","2. On the Telegram app, you need to search and look for a contact called the Botfather.\n","3. You can use the `/start` command to get a list of options or directly use the `/newbot` command to create a new bot for yourself.\n","4. Then answer the set of questions by providing a name for and username for your bot.\n","5. At the end you will be provided with an API token that you can use to work with the bot. This API token is what we need to replace in the .env.dev file. `telegram_response_bot.py` file.\n","\n","<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/f2MqxCd/Screenshot-2024-07-26-at-14-23-02.png\" alt=\"Screenshot-2024-07-26-at-14-23-02\" border=\"0\"></a>"],"metadata":{"id":"zC344Wj19pcE"}},{"cell_type":"markdown","source":["Once you have performed both these steps, you are now ready to run your RAG app as a Telegam bot. You need to run the command `python telegram_response_bot.py ` from the command line of your Github Space and this starts a thread that listens for messages on your bot. Once a message is received, it then hands off to the RAG app and provides the generated response.\n","\n","You can easily share this Pillpal bot with your friends and family and ask them to try it!"],"metadata":{"id":"aOutTlUR_zmC"}},{"cell_type":"markdown","source":["# Step 3: Evaluation of PillPal"],"metadata":{"id":"Y_4zSQWPQM-R"}},{"cell_type":"markdown","source":["Now that we have deployed and made our app live, we need to consistently monitor how it performs. This is also a way for us to understand what questions are being asked by our users and whether the bot is responding correctly or not. For this we will make use of the Langsmith part of the Langchain library."],"metadata":{"id":"m9wzLbcQptfZ"}},{"cell_type":"markdown","source":["As the first step, we have to create a validation dataset that we can use for evaluation. There are several ways to go about doing this:\n","\n","1. Launch your app in beta and get some trial users to start interacting with the bot/chat interface and identify common patterns and questions that are being asked. Manually, write your own answers to these questions and perform evaluations using that.\n","2. Come up with a list of 5-10 questions and manually search for the answers of these questions in the PDF and create this as your evaluation dataset -> this is what we are going to do below.  \n","3. You could also make use of another LLM to come up with these questions and answers which is called creating a synthetic dataset. This would work well if you use higher level models like GPT-4 but you need to keep in mind that they have to be relevant to the context of your leaflet."],"metadata":{"id":"Gvj_e6UYon-V"}},{"cell_type":"markdown","source":["### Creating a base evaluation dataset"],"metadata":{"id":"b-H03qVVaMkH"}},{"cell_type":"markdown","source":["To ensure that our application is functioning correctly and effectively answering questions, we have implemented a basic sanity check. This involves a set of 8-10 questions that I have manually curated and answered after thoroughly reviewing the content of the PDF document. These questions are designed to cover a wide range of topics and complexities within the document, ensuring that they test various aspects of our QnA bot's capabilities. By comparing the answers generated by our bot to these manually prepared responses, we can gauge the accuracy and reliability of our system. This step is crucial as it helps us identify any discrepancies or areas needing improvement before the application is deployed for wider use. Additionally, it provides an initial layer of validation and builds confidence in the application's performance among users and stakeholders."],"metadata":{"id":"6xTfANXXXd5P"}},{"cell_type":"markdown","source":["## 📝 Learner Task:\n","\n","Please create a set of question and correct answer pairs here to use as your evaluation dataset. We have provided the first two questions as examples but feel free to overwrite and add your own."],"metadata":{"id":"Vv6vi_EAT89n"}},{"cell_type":"code","source":["examples = [\n","    (\n","        \"Can it be taken by pregnant women?\",\n","        \"No, it should not be taken by pregnant women.\",\n","    ),\n","    (\n","        \"Can it be given to children?\",\n","        \"No, it is not recommended for use in this population.\",\n","    ),\n","    (\n","        \"What should I do if I miss a dose?\",\n","        \"If you forgot to inject a dose of wegovy and it is 5 days or less since you should have used it, use it as soon as you remember. Then inject your next dose as usual on your scheduled day. If it is more than 5 days since you should have used wegovy, skip the missed dose and inject your next dose as usual on your next scheduled day.\"\n","    ),\n","    (\n","        \"What is this medicine used for?\",\n","        \"wegovy is use for weight management and to reduce the risk of serious heart issues.\"\n","    ),\n","    (\n","        \"Is it safe to drive or operate machinery while taking this medicine?\",\n","        \"wegovy is unlikely to affect your ability to drive and use machines.\"\n","    ),\n","    (\n","        \"What are the common serious side effects?\",\n","        \"Complications of diabetic eye disease (diabetic retinopathy).\"\n","    ),\n","    (\n","        \"What is the recommended dose for adolescents?\",\n","        \"The same dose as for adults, which is 2.4mg weekly.\"\n","    ),\n","    (\n","        \"What should I do if I experience any side effects?\",\n","        \"Talk to your doctor, pharmacist or nurse.\"\n","    ),\n","    (\n","        \"What is the active substance of wegovy?\",\n","        \"The active substance is semaglutide.\"\n","    ),\n","    (\n","        \"Who is the manufacturer?\",\n","        \"The manufacturer is Novo Nordisk A/S.\"\n","    ),\n","    (\n","        \"What is the price of this medicine?\",\n","        \"This information is not provided in the given context.\"\n","    ),\n","    (\n","        \"Where can I buy this medicine?\",\n","        \"This information is not provided in the given context.\"\n","    )\n","]"],"metadata":{"id":"wXFxOClWQPbe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once we have successfully created our dataset, the next step involves registering it with the Langsmith client. This process integrates the dataset into our evaluation framework. By registering the dataset, we effectively add it to the list of datasets available for testing and validating our model. In general, you might create multiple datasets to test various aspects of the QnA bot and might run different types of evaluations on it.\n","\n","In this case, we are running a test for general correctness of the QnA bot - while this does include checks for hallucinations -> we have added examples where the bot should not have an answer and must say so. But there are additional datasets that you might create with separate evaluation metrics to explicitly check for hallucination and fact-checking."],"metadata":{"id":"x82VVhfGqJ9S"}},{"cell_type":"code","source":["from langsmith import Client\n","\n","client = Client()"],"metadata":{"id":"hGqC94J7qSEn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langsmith import Client\n","\n","client = Client()\n","\n","dataset_name = \"PillPall Accuracy Test Dataset\"\n","dataset = client.create_dataset(dataset_name=dataset_name)\n","inputs, outputs = zip(\n","    *[({\"input\": input}, {\"expected\": expected}) for input, expected in examples]\n",")\n","client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)"],"metadata":{"id":"2EbuuZNMqTRk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once the above cells are run, you should now be able to see the dataset created in the dataset folder in your Langsmith project.\n","\n","![QA Dataset](https://i.ibb.co/sH5dv86/Xnapper-2024-06-11-20-58-53.png)"],"metadata":{"id":"EqUUjzJUq_F5"}},{"cell_type":"markdown","source":["Let's run the evaluation of our app using this dataset.\n","\n","By executing the code below, we will first be calling our app for each of the questions in our QA dataset. Once the answers have been generated, we need to evaluate it with the golden standard answers that we have written manually. But the big question is always: how can we compare two texts, what metrics shall we use?\n","\n","One of the easier ways to do this is by using another LLM to compare the two responses and tell you whether they match or not. This is also referred to as 'LLM-as-a-judge'. In this case, since we have only 5-10 examples you can easily do this manually but typically your evaluation datasets will contain a lot of examples and this method would not work.\n","\n","We will use the off-the-shelf evaluator that Langsmith provides us called `cot_qa` that stands for Chain of Thought Question Answer. This basically refers to a pre-filled prompt that is used when asking the \"Judge LLM\" to rate whether the two answers are comparable or not.\n","\n","Typically we make use of a bigger, more powerful LLM to act as the judge for what the smaller, cheaper LLM has generated. However, since our dataset is small and quite easy we stick with `gpt-4o-mini`"],"metadata":{"id":"kcZrdxNVrci2"}},{"cell_type":"code","source":["from langsmith import Client\n","from langsmith.evaluation import LangChainStringEvaluator, evaluate\n","\n","eval_llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o-mini\", openai_api_key=userdata.get('OPENAI_API_KEY'))\n","cot_qa_evaluator = LangChainStringEvaluator(\"cot_qa\", config={\"llm\": eval_llm})\n","\n","client = Client()\n","evaluate(\n","    rag_chain,\n","    data=dataset_name,\n","    evaluators=[cot_qa_evaluator],\n",")"],"metadata":{"id":"vMe1SzrvrKMs","colab":{"base_uri":"https://localhost:8080/","height":807,"referenced_widgets":["c1901bd8a25b47eaa027608c1e0109b0","fe4c63c4b4fa4f1095f62bc72df06fe3","a74efece9fa048b0a934c53a6201a5d0","ffab70b63b264959a0cc391245a6a1a0","cdd5b90cc96e458aa8215292f74a1570","39dbd670cc6e481aa368fced34abd035","c844779963a341549bc3227165990066","e18022e193f54025b7d88dd24eed7760","b4b6419016c2423190372aadc1478587","7347f326093443709c4583ffb9c748ac","025eef662e764694b7a67b135cf73acf"]},"executionInfo":{"status":"ok","timestamp":1739752814868,"user_tz":-60,"elapsed":53756,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"38ef740b-43ea-48d3-85e2-606482de6285"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-21-e8b1a35096c4>:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n","  eval_llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o-mini\", openai_api_key=userdata.get('OPENAI_API_KEY'))\n"]},{"output_type":"stream","name":"stdout","text":["View the evaluation results for experiment: 'cooked-stamp-35' at:\n","https://smith.langchain.com/o/2e249804-10fa-4cd7-b74a-39ef5a4f468c/datasets/5195a685-f857-4513-b16c-80887f17d948/compare?selectedSessions=6a33c3ca-bd41-4fa2-89da-27d7870b8469\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1901bd8a25b47eaa027608c1e0109b0"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<ExperimentResults cooked-stamp-35>"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>inputs.input</th>\n","      <th>outputs.output</th>\n","      <th>error</th>\n","      <th>reference.expected</th>\n","      <th>feedback.COT Contextual Accuracy</th>\n","      <th>execution_time</th>\n","      <th>example_id</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Where can I buy this medicine?</td>\n","      <td>I cannot answer the question based on the prov...</td>\n","      <td>None</td>\n","      <td>This information is not provided in the given ...</td>\n","      <td>1</td>\n","      <td>1.031631</td>\n","      <td>2e931ddf-72fd-4087-a5ef-4450e1cdfbe7</td>\n","      <td>f7960d37-838e-44ca-abda-ece569c12a5b</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What is the price of this medicine?</td>\n","      <td>I cannot answer the question based on the prov...</td>\n","      <td>None</td>\n","      <td>This information is not provided in the given ...</td>\n","      <td>1</td>\n","      <td>0.723210</td>\n","      <td>fe68058e-1c63-4936-b094-e3e101d085c6</td>\n","      <td>5c97fa91-63e3-4b2d-82d4-016eeae4ee76</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Who is the manufacturer?</td>\n","      <td>The manufacturer is Novo Nordisk A/S, located ...</td>\n","      <td>None</td>\n","      <td>The manufacturer is Novo Nordisk A/S.</td>\n","      <td>1</td>\n","      <td>1.295857</td>\n","      <td>7618d909-e601-437a-8c17-ef920fcf45a4</td>\n","      <td>98c580f6-a567-46b9-b39a-2b0dbc12af5e</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What is the active substance of wegovy?</td>\n","      <td>I cannot answer the question based on the prov...</td>\n","      <td>None</td>\n","      <td>The active substance is semaglutide.</td>\n","      <td>0</td>\n","      <td>0.877307</td>\n","      <td>71386ec2-d729-41ac-818d-6d1ca1d4fe10</td>\n","      <td>3a121a7a-1aeb-4633-a351-5c35770d9ee5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What should I do if I experience any side effe...</td>\n","      <td>If you get any side effects, talk to your doct...</td>\n","      <td>None</td>\n","      <td>Talk to your doctor, pharmacist or nurse.</td>\n","      <td>1</td>\n","      <td>2.704661</td>\n","      <td>3003248e-625b-4b44-9edc-876f3b70eae5</td>\n","      <td>189aa66f-1ccd-46a2-9247-cc68ea1614fd</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>What is the recommended dose for adolescents?</td>\n","      <td>The recommended dose for adolescents is the sa...</td>\n","      <td>None</td>\n","      <td>The same dose as for adults, which is 2.4mg we...</td>\n","      <td>1</td>\n","      <td>1.590484</td>\n","      <td>5f3e70c0-650c-4d11-b092-d23e0d099d6e</td>\n","      <td>bf1b620f-bf52-4921-8bcc-689c5794c303</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>What are the common serious side effects?</td>\n","      <td>The common serious side effects may affect up ...</td>\n","      <td>None</td>\n","      <td>Complications of diabetic eye disease (diabeti...</td>\n","      <td>1</td>\n","      <td>1.125853</td>\n","      <td>992929af-c7c0-4e69-8494-5f2d1da80310</td>\n","      <td>5845c02a-3b66-4e1b-884d-0d342328b2e7</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Is it safe to drive or operate machinery while...</td>\n","      <td>Wegovy is unlikely to affect your ability to d...</td>\n","      <td>None</td>\n","      <td>wegovy is unlikely to affect your ability to d...</td>\n","      <td>1</td>\n","      <td>1.406608</td>\n","      <td>fca4f5a2-2391-4e2c-b752-d32ffcab9f73</td>\n","      <td>e2124bea-f8aa-4ee6-8149-61229f59c87b</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>What is this medicine used for?</td>\n","      <td>This medicine, wegovy, is used for weight loss...</td>\n","      <td>None</td>\n","      <td>wegovy is use for weight management and to red...</td>\n","      <td>1</td>\n","      <td>1.410895</td>\n","      <td>e23bd620-fa63-421c-94e8-8ab3a6055d8a</td>\n","      <td>8e13c1f9-2407-4ed9-b16f-d14306519463</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>What should I do if I miss a dose?</td>\n","      <td>I cannot answer the question based on the prov...</td>\n","      <td>None</td>\n","      <td>If you forgot to inject a dose of wegovy and i...</td>\n","      <td>0</td>\n","      <td>0.809779</td>\n","      <td>921eca41-f10a-43b1-8381-5acbc4d9e5ed</td>\n","      <td>346e9385-dd16-41f1-a1fd-6c2ef658024e</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Can it be given to children?</td>\n","      <td>The safety and efficacy of wegovy in children ...</td>\n","      <td>None</td>\n","      <td>No, it is not recommended for use in this popu...</td>\n","      <td>1</td>\n","      <td>1.032667</td>\n","      <td>bd156e32-2382-4a7f-940f-585730812ef7</td>\n","      <td>d643861d-10e4-4204-b035-54ade50aeae1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Can it be taken by pregnant women?</td>\n","      <td>This medicine should not be used during pregna...</td>\n","      <td>None</td>\n","      <td>No, it should not be taken by pregnant women.</td>\n","      <td>1</td>\n","      <td>2.245261</td>\n","      <td>7e370bee-1738-4d67-b0ee-53fb28d81b04</td>\n","      <td>7706eaea-1e5b-465d-8a4c-dc3b6446c019</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["Let's run the evaluation on the dataset. You get the links to where you can track the run and at the end the output is also printed here."],"metadata":{"id":"nd_6YQfQsvgw"}},{"cell_type":"markdown","source":["After initiating the evaluation of our QnA bot using the dataset we registered, you will be able to observe several key performance metrics. These metrics include the percentage of questions answered correctly, which provides a direct measure of the bot's accuracy. You will also see the duration of the test, which gives insight into the efficiency of the bot under testing conditions. Additionally, the evaluation will report on costs and latency, offering a broader view of the bot's operational performance.\n","\n","This initial evaluation serves as a preliminary indication of how well your bot is performing. As the bot encounters more users and a diverse array of questions, it's crucial to continually update and adapt your baseline test dataset. This iterative process ensures that the bot remains effective and responsive to the evolving needs and contexts it will encounter in real-world applications.\n","\n","![Evaluation Test results](https://i.ibb.co/txtzhtD/Xnapper-2024-06-16-11-32-28.png)"],"metadata":{"id":"C5PPIGVIYU8Z"}},{"cell_type":"markdown","source":["## 📝 Learner Task:\n","\n","Now that you have an end to end RAG chatbot up and running, you can try to stress-test your bot by asking all kinds of questions - both relevant and irrelevant. What kind of responses does it generate? How often does it hallucinate?"],"metadata":{"id":"Bj_PnIs8aouf"}},{"cell_type":"code","source":["\n","# System message prompt template\n","system_message_prompt = SystemMessagePromptTemplate.from_template(\n","    \"You are an expert assistant that answers questions about medical information based on the Patient Information Leaflet.\"\n",")\n","\n","# Human message prompt template\n","human_message_prompt = HumanMessagePromptTemplate.from_template(\n","    \"\"\"Context: {context}\n","\n","    Question: {question}\"\"\"\n",")\n","\n","# Chat prompt template\n","qna_prompt_template = ChatPromptTemplate.from_messages(\n","    [system_message_prompt, human_message_prompt]\n",")\n","\n","rag_chain = (\n","    {\"context\": itemgetter(\"input\") | retriever | format_docs,\n","     \"question\": RunnablePassthrough()}\n","    | qna_prompt_template\n","    | llm\n","    | StrOutputParser()\n",")\n"],"metadata":{"id":"aRwtJcs4etmZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"Is wegovy the same medicine as ozempic?\"\n","rag_chain.invoke({\"input\": question})"],"metadata":{"id":"CgQ9dSJJa61b","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1739755174724,"user_tz":-60,"elapsed":1964,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"2860e6b5-a391-474e-9360-dfe3f6a30147"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Wegovy and Ozempic both contain the active substance semaglutide, but they are used for different purposes. Wegovy is specifically indicated for weight management, including weight loss and maintenance, in adults and adolescents with obesity or overweight with weight-related health problems. Ozempic, on the other hand, is primarily used for the management of type 2 diabetes. While they share the same active ingredient, their dosages and indications differ. Always consult your doctor for personalized medical advice.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["question = \"Should I take wegovy?\"\n","rag_chain.invoke({\"input\": question})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"uCBSKJFtdtBA","executionInfo":{"status":"ok","timestamp":1739755198794,"user_tz":-60,"elapsed":3447,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"6f3337fa-f22e-4a65-df83-120bb61a1df9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Whether you should take Wegovy depends on several factors, including your medical history, current health status, and specific weight management needs. Wegovy is indicated for adults with a BMI of 30 kg/m² or greater (obesity) or a BMI of 27 kg/m² and less than 30 kg/m² (overweight) with weight-related health problems. It is also used for adolescents aged 12 years and above who have obesity and weigh more than 60 kg.\\n\\nBefore starting Wegovy, you should consult your doctor to discuss:\\n\\n1. Your eligibility based on your BMI and health conditions.\\n2. Any potential allergies to semaglutide or other ingredients in Wegovy.\\n3. Any other medications you are currently taking, especially if you have diabetes or are on insulin or sulfonylureas, as this may increase the risk of low blood sugar.\\n4. Any existing health issues, such as kidney problems or a history of pancreatitis.\\n\\nYour doctor will help determine if Wegovy is appropriate for you and guide you on how to use it safely.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["question = \"In which page does it describe the dose?\"\n","rag_chain.invoke({\"input\": question})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"td5CDY7NdzVy","executionInfo":{"status":"ok","timestamp":1739755217279,"user_tz":-60,"elapsed":1438,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"cd050e12-ee64-4117-c618-3d968f2ff3b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The information about the dose is described in the section labeled \"Week 1–4\" and continues through \"From week 17,\" which outlines the dose escalation schedule. This information is typically found on the page that provides instructions for setting the dose and administering the injection.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["question = \"What is the weather today?\"\n","rag_chain.invoke({\"input\": question})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"884uxsyUeAg1","executionInfo":{"status":"ok","timestamp":1739755247593,"user_tz":-60,"elapsed":18224,"user":{"displayName":"Ruth Vilar","userId":"17604228112721847304"}},"outputId":"22265e07-6ac6-455e-a1aa-876b79132d7e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I'm sorry, but I cannot provide information about the weather. My expertise is in medical information based on the Patient Information Leaflet. If you have any questions related to that, feel free to ask!\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]}]}